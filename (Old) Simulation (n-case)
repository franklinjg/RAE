"""
Necessary Libraries for Analysis Replication:
-----------------------------------------------------
To replicate my analysis, the libraries used in this code must be installed. If you encounter any issues with the installations, execute the following commands in your terminal:

For Python 2.x:
    pip install "library_name"

For Python 3.x:
    pip3 install "library_name"

Seed for Reproducibility:
-----------------------------------------------------
The random seed is set to 4862 to ensure that the results are reproducible. It's important to note that setting a fixed seed is not the most efficient approach for achieving randomness. The fixed seed is used here only to meet a specific requirement. For scenarios involving large numbers, consider utilizing quasi-random number generators, as they provide a more evenly distributed sequence of numbers and actively prevent clustering.

Special thanks to my friend Nishanth for his helpful comments. P.D. My code does not comply with PEP 8 standards. I am aware of this and I am working on it.
"""


import numpy as np
import pandas as pd
from sympy import Matrix
import scipy.io
from scipy.optimize import minimize
from scipy.special import comb
import matplotlib.pyplot as plt
import networkx as nx


np.random.seed(4862)

############################################################################################################################################################################

# Generating the constants and storing them 

phi = 0.20                 # This is the importance of social connections to legislators which is used in the computation of the Katz-Bonacich centrality vector. 
Psi = 0.10                 # This is the densitiy of the epsilon terms which is used in the computation of the pivotal probabilities.
X = 5.0                    # This is the budget of the interest groups which is used in the computation of the optimal transfers.
q = 0.5                    # This is the value of q which is used in the computation of the pivotal probabilities. (q-rule).      
phistar = 2*Psi*phi        # This is the value of phi* which is used in the computation of the Katz-Bonacich centrality vector.
vmax = 1.0                 # This is the maximum value of the diagonal elements of the matrix V.

# Number of Legislators. Depending on your computer this code will be able to run for a large n. 

n = 100

############################################################################################################################################################################

"""
This section generates the network of legislators. The network is generated using the NetworkX library. 
"""
 
def generate_adjusted_matrix(n):                # This function generates an n x n matrix G with the sum of each row equal to 1. This is an assumption I made in my paper. 
    G = np.zeros((n, n))                        # This creates a matrix of zeros with size n x n
    
    possible_values = [0.5, -0.5, 1, 0]         # This defines possible values for the matrix entries. Assumption made in my paper. 
    
    for i in range(n):                          # Loop over each row of the matrix
        row_sum = 0                             # Initialise sum of the current row
        for j in range(n):                      # Loop over each column in the current row
            if i == j:
                continue                        # This skips diagonal elements
            if j == n - 1:  
                G[i, j] = 1 - row_sum           # This adjusts the last element in the row to ensure the sum is 1
            else:                               # Randomly choose a value from the possible values
                value = np.random.choice(possible_values)           
                if row_sum + value > 1 or (j == n - 2 and row_sum + value + 0.5 > 1):   # This ensures the row sum does not exceed 1
                    value = 1 - row_sum - 0.5 if np.random.rand() > 0.5 else 0
                G[i, j] = value                  # Assign the chosen value to the matrix
                row_sum += value                 # Updates the row sum

    return G

def store_matrix_entries(matrix):
    stored_entries = {}
    n = matrix.shape[0]  
    for i in range(n):
        for j in range(n):
            identifier = f"g_{i+1}{j+1}"  
            stored_entries[identifier] = matrix[i, j]
    return stored_entries

def sum_matrix_range(entries_dict, start, end):
    sum_range = 0
    collecting = False
    for key in sorted(entries_dict.keys()):
        if key == start:
            collecting = True                  # Start collecting values
        if collecting:
            sum_range += entries_dict[key]
        if key == end:
            break                               # Stops collecting values after the end key is found
    return sum_range                            # Returns the calculated sum



Gn = generate_adjusted_matrix(n)                # Generate the adjusted matrix
entries_dict = store_matrix_entries(Gn)         # Storing matrix entries in a dictionary



G_transpose = Gn.T           # This stores the transpose of the matrix Gn

#print(Gn)                   # Remove the # if you want to see the matrix Gn
#print(G_transpose)          # Remove the # if you want to see the matrix Gn transposed

############################################################################################################################################################################
 
  

# Function to generate an n x n diagonal matrix V and save the diagonal elements as v1, v2, ..., vn
def generate_and_save_diagonal_matrix(n):
    # Define the possible values for the diagonal elements
    possible_values_diagonal = [-1, 1, 0.5, -0.5]
    
    V = np.zeros((n, n))
    
    # Fill the diagonal elements of the matrix with random choices from the possible values
    for i in range(n):
        V[i, i] = np.random.choice(possible_values_diagonal)
    
    # Save the matrix with a name 'Vnxn.npy', where m is replaced with the actual size
    filename = f'V{n}.npy'
    np.save(filename, V)
    
    # Extract and save the diagonal elements as v1, v2, ..., vn
    v_elements = np.diag(V)
    v_dict = {f'v{i+1}': v_elements[i] for i in range(n)}
    
    # Return the matrix, the filename it was saved as, and the diagonal elements
    return V, filename, v_dict

# Example usage:

V, filename, v_dict = generate_and_save_diagonal_matrix(n)

print(V, filename, v_dict)


############################################################################################################################################################################

# Checking if Assumption 1 holds 

def check_inequality(Psi, vmax, phi, X):
    value_inside = vmax + phi + np.log(2*X)
    result = Psi * value_inside
    print(f"Computed result: {result}")  
    return result < 0.5

inequality_holds = check_inequality(Psi, vmax, phi, X)
print("Does the inequality hold strictly? :", inequality_holds)

############################################################################################################################################################################

# Checking if Assumption 2 holds 

# Step 1: Computing the matrix (I - 2 * phi * Psi * Gn)
I = np.eye(n)  # Identity matrix of size nxn
matrix_to_invert = I - 2 * phi * Psi * Gn


# Step 2: Check if the matrix is invertible (determinant is not zero)
is_invertible = np.linalg.det(matrix_to_invert) != 0

# Step 3: If invertible, compute the inverse and the Katz-Bonacich vector
if is_invertible:
    inverse_matrix = np.linalg.inv(matrix_to_invert)
    # Step 4: Multiply the inverse by a vector of ones
    katz_bonacich_vector = inverse_matrix.dot(np.ones(n))
    # Step 5: Check if all elements of the resulting vector are positive
    all_positive = np.all(katz_bonacich_vector > 0)
else:
    all_positive = False  # If the matrix is not invertible, the assumption does not hold

# Result
assumption_2_holds = is_invertible and all_positive
print("Does Assumption 2 hold? :", assumption_2_holds)

############################################################################################################################################################################

# Assumption 3 is always satisfied. 

############################################################################################################################################################################

# Define the solve_system function
def calculate_pivotal_probabilities(x):
    n = len(x)
    pivotal_probs = np.zeros(n)
    for i in range(n):
        others = np.concatenate((x[:i], x[i+1:]))
        for j in range(n//2):
            pivotal_probs[i] += comb(n - 1, j) * np.prod(others[:j]) * np.prod(1 - others[j:])
    return pivotal_probs / (2**(n - 1))

# Define the solve_system function

# Note that here the notation chages slightly. I did this for simplicity as it was easier to write x. 



def solve_system(v, phi, Psi, Gn, pivotal_prob_func, tolerance=1e-6, max_iterations=1000): # if there has not been convergence after 1000 iterations, the function will raise an error.
    n = len(v)
    x = np.full(n, 0.5)  # This is the initial guess for the probabilities. It can be anything as long as it's in (0, 1) but 0.5 is a good starting point.

    for iteration in range(max_iterations):
        pivotal_probs = pivotal_prob_func(x)  # Calculate pivotal probabilities
        x_new = np.empty(n)
        for i in range(n):
            # Calculate the new x_i using the given formula
            sum_gx = sum(Gn[i, j] * (1 - x[j]) for j in range(n))
            x_new[i] = q + Psi * v[i] * pivotal_probs[i] + Psi * phi * sum_gx
        
        # Checking for convergence
            
        if np.allclose(x, x_new, atol=tolerance):
            return x  # Converged
        x = x_new  # Update x for the next iteration

    raise ValueError("The system did not converge within the maximum number of iterations") # If this doesn't work then increase the maximum number of iterations.



# Define the compute_jacobian function
def compute_jacobian(x, pivotal_prob_func, h=1e-5):
    n = len(x)
    jacobian = np.zeros((n, n))
    
    for i in range(n):
        for j in range(n):
            x1 = x.copy()
            x2 = x.copy()
            x1[j] -= h/2
            x2[j] += h/2
            f1 = pivotal_prob_func(x1)
            f2 = pivotal_prob_func(x2)
            jacobian[i, j] = (f2[i] - f1[i]) / h

    return jacobian



v_values = np.array([v_dict[f'v{i+1}'] for i in range(n)])

# Now we can call solve_system and compute_jacobian
x_star = solve_system(v_values, phi, Psi, Gn, calculate_pivotal_probabilities)
jacobian_matrix = compute_jacobian(x_star, calculate_pivotal_probabilities)

print("The pivotal probabilities are:", calculate_pivotal_probabilities(x_star))
print(jacobian_matrix)

transposed_matrixJ = jacobian_matrix.T

print(transposed_matrixJ)

############################################################################################################################################################################

I = np.eye(n)                    # This creates an dentity matrix of size n x n

ones_vector = np.ones((n, 1))    # This creates a vector of ones of size n x 1
 
V_diag = np.diag(V)              # This extracts the diagonal elements of the matrix V

matrix_inside_brackets = I - (phistar * G_transpose + Psi * np.diag(transposed_matrixJ - V_diag)) # Calculate the matrix inside the brackets

inverted_matrix = np.linalg.inv(matrix_inside_brackets)    # This calculates the inverse of the matrix inside the brackets

b_M = inverted_matrix.dot(ones_vector)   # This calculates the Katz-Bonacich centrality vector

print("The Katz-Bonacich centrality vector b_M is:")    # This just looks nice, you can get rid of it if you want.
print(b_M)
b_M_array = b_M.flatten()
print("Matrix as array:")
print(b_M_array)   
###################################################################################################################################################################################
"""
This part of the code solves the maximisation problem of the interest groups to get the vector of transfers.
"""

# Define the objective function to be maximized (negative because minimize() finds the minimum)
def objective_function(s, b_M):
    return -np.sum(b_M * np.log(s))

# Define the constraints of the optimization problem (sum of s must be equal to X)
constraints = ({'type': 'eq', 'fun': lambda s: np.sum(s) - X})

# Define the bounds for each transfer, s must be greater than 0
bounds = [(1e-5, None) for _ in range(len(b_M))]

# Initial guess for the values of s
initial_s = np.full(len(b_M), X / len(b_M))

# Run the optimization algorithm
result = minimize(objective_function, initial_s, args=(b_M_array), bounds=bounds, constraints=constraints)

# The optimal vector of transfers s*
s_optimal = result.x

# Display the optimal transfers
print("Optimal transfers vector s*:")
print(s_optimal)
###################################################################################################################################################################################

df = pd.DataFrame(Gn)

# Initialize the graph object 'Gn'
Gn = nx.Graph()

# Iterate through the DataFrame to add edges based on conditions
for i in range(len(df)):
    for j in range(len(df.columns)):
        if i != j:  # Avoid self-loops
            value = df.iloc[i, j]
            if value != 0:
                if value == 1:
                    Gn.add_edge(i, j, color='black', style='solid')
                elif value == 0.5:
                    Gn.add_edge(i, j, color='blue', style='dashed')  # Corrected to 'dashed'
                elif value == -0.5:
                    Gn.add_edge(i, j, color='red', style='dashed')  # Corrected to 'dashed'


# Generate positions for all nodes
pos = nx.spring_layout(Gn)

# Draw nodes
nx.draw_networkx_nodes(Gn, pos, node_color='lightgrey')

# Extract edge attributes for drawing
edges = Gn.edges(data=True)

# Draw edges with specific styles and colors
for u, v, d in edges:
    nx.draw_networkx_edges(Gn, pos, edgelist=[(u, v)], width=1, edge_color=d['color'], style=d['style'])

# Draw labels
nx.draw_networkx_labels(Gn, pos)

# Turn off the axis
plt.axis('off')

# Show plot
plt.show()


print(Gn)

###################################################################################################################################################################################
